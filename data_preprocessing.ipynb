{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sarag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sarag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import re\n",
    "import stanza\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eng_train0</th>\n",
       "      <td>I supported Barack Obama. I thought it was abs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_train1</th>\n",
       "      <td>what to hell with that!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_train2</th>\n",
       "      <td>and the stupidity of the haters continues, thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_train3</th>\n",
       "      <td>Alberta has been in debt under the Conservativ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_train4</th>\n",
       "      <td>The TV is in Channel Search mode, and I have p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_train98995</th>\n",
       "      <td>My bad for thinking you could get off your nea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_train98996</th>\n",
       "      <td>It's fixed now.  Jackman Wilson Editorial page...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_train98997</th>\n",
       "      <td>Could certainly be inconvenient for consumers ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_train98998</th>\n",
       "      <td>It is sad that Hawaii has the lowest turnout. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng_train98999</th>\n",
       "      <td>You don't now your cars or collector car value...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98637 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             text  label\n",
       "id                                                                      \n",
       "eng_train0      I supported Barack Obama. I thought it was abs...      0\n",
       "eng_train1                                what to hell with that!      1\n",
       "eng_train2      and the stupidity of the haters continues, thi...      1\n",
       "eng_train3      Alberta has been in debt under the Conservativ...      0\n",
       "eng_train4      The TV is in Channel Search mode, and I have p...      0\n",
       "...                                                           ...    ...\n",
       "eng_train98995  My bad for thinking you could get off your nea...      1\n",
       "eng_train98996  It's fixed now.  Jackman Wilson Editorial page...      0\n",
       "eng_train98997  Could certainly be inconvenient for consumers ...      0\n",
       "eng_train98998  It is sad that Hawaii has the lowest turnout. ...      0\n",
       "eng_train98999  You don't now your cars or collector car value...      0\n",
       "\n",
       "[98637 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(root_path, 'data')\n",
    "train_set = pd.read_csv(os.path.join(data_path, 'train_2025.csv'), header=0, index_col='id')\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and Lemmatize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_normalize(text, stopwords):\n",
    "    \"\"\"Tokenizes, lemmatizes, lowercases and removes stop words.\n",
    "    \n",
    "    this function takes in a path to a song, reads the song file,\n",
    "    tokenizes it into words, then lemmatizes and lowercases these words.\n",
    "    finally, stopwords given to the function are removed from the list of song lemmas\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str\n",
    "        a path to a text file\n",
    "    stopwords : list of strings\n",
    "        stopwords that should be removed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    normalized_song : list of strings\n",
    "        a song represented as a list of its lemmas\n",
    "    \"\"\"\n",
    "    \n",
    "    nlp = stanza.Pipeline(lang='en', processors='tokenize, lemma',  verbose=False)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    result = [word.lemma.lower()\n",
    "               for token in nlp(text).iter_tokens()\n",
    "               for word in token.words\n",
    "               if word.lemma.lower() not in stopwords]\n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 652/98637 [18:55<36:03:44,  1.32s/it]"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "completed_preprocessed_text = []\n",
    "for sentence in tqdm(train_set.text):\n",
    "    token_list = tokenize_and_normalize(sentence, stop_words)\n",
    "    if len(token_list) > 0:\n",
    "        preprocessed_sentence = token_list[0]\n",
    "        for token in token_list[1:]:\n",
    "            preprocessed_sentence += (' ' + token)\n",
    "    else:\n",
    "        preprocessed_sentence = ''\n",
    "    completed_preprocessed_text.append(preprocessed_sentence)\n",
    "train_set.insert(1, 'preprocessed_text', completed_preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Except that Desmond played first base last nig...</td>\n",
       "      <td>except desmond play first base last night tapi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What i find funny is the loyalty and blindness...</td>\n",
       "      <td>find funny loyalty blindness english community...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Read the article  not just the headline &amp; you ...</td>\n",
       "      <td>read article headline find</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speaking of a horses backside  is that where y...</td>\n",
       "      <td>speak horse backside head</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Barone- gee are you dumb.  No other wo...</td>\n",
       "      <td>michael barone gee dumb word need</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98995</th>\n",
       "      <td>the libs could just pass a law that pulls them...</td>\n",
       "      <td>lib could pass law pull treaty easily exite ball</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98996</th>\n",
       "      <td>Really? How does this post in any way relate t...</td>\n",
       "      <td>really post way relate article article take pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98997</th>\n",
       "      <td>Hey illegals if your reading this  get the hel...</td>\n",
       "      <td>hey illegal read get hell country</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98998</th>\n",
       "      <td>Excellent description \"he playground bully  ol...</td>\n",
       "      <td>excellent description playground bully old lit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98999</th>\n",
       "      <td>As my grandpa used to say  \"If you ask a stupi...</td>\n",
       "      <td>grandpa use say ask stupid question complain a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "id                                                         \n",
       "0      Except that Desmond played first base last nig...   \n",
       "1      What i find funny is the loyalty and blindness...   \n",
       "2      Read the article  not just the headline & you ...   \n",
       "3      Speaking of a horses backside  is that where y...   \n",
       "4      Michael Barone- gee are you dumb.  No other wo...   \n",
       "...                                                  ...   \n",
       "98995  the libs could just pass a law that pulls them...   \n",
       "98996  Really? How does this post in any way relate t...   \n",
       "98997  Hey illegals if your reading this  get the hel...   \n",
       "98998  Excellent description \"he playground bully  ol...   \n",
       "98999  As my grandpa used to say  \"If you ask a stupi...   \n",
       "\n",
       "                                       preprocessed_text  label  \n",
       "id                                                               \n",
       "0      except desmond play first base last night tapi...      0  \n",
       "1      find funny loyalty blindness english community...      0  \n",
       "2                             read article headline find      0  \n",
       "3                              speak horse backside head      1  \n",
       "4                      michael barone gee dumb word need      1  \n",
       "...                                                  ...    ...  \n",
       "98995   lib could pass law pull treaty easily exite ball      1  \n",
       "98996  really post way relate article article take pa...      0  \n",
       "98997                  hey illegal read get hell country      1  \n",
       "98998  excellent description playground bully old lit...      1  \n",
       "98999  grandpa use say ask stupid question complain a...      1  \n",
       "\n",
       "[99000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save result as a new file to avoid re-normalize\n",
    "train_set.to_pickle(os.path.join(data_path, 'train_2024_tokenized.pkl'))\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
